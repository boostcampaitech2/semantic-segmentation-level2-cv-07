{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6fe377e-916c-4687-ae95-7f3f47e05b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as mutils\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006cf3ae-ea56-4b52-93cd-33a03553b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db4f7fe8-3803-4fe7-b6f8-35dd8dffa756",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "# config file 들고오기\n",
    "# swin_tiny\n",
    "# cfg = Config.fromfile('./configs/_base_/my_seg/swin.py')\n",
    "# cfg.work_dir = './work_dirs/swin_base'\n",
    "\n",
    "# swin_base\n",
    "# cfg = Config.fromfile('./configs/_base_/my_seg/swin_base.py')\n",
    "# cfg.work_dir = './work_dirs/real_swin_base'\n",
    "\n",
    "# swin_large\n",
    "cfg = Config.fromfile('./configs/_base_/my_seg/swin_large.py')\n",
    "cfg.work_dir = './work_dirs/real_swin_large'\n",
    "\n",
    "cfg.data.samples_per_gpu = 8\n",
    "cfg.data.workers_per_gpu = 4\n",
    "cfg.seed = 2021\n",
    "cfg.gpu_ids = [0]\n",
    "\n",
    "epoch = 'epoch_16'\n",
    "\n",
    "cfg.seed = 2021\n",
    "cfg.gpu_ids = [0]\n",
    "\n",
    "# image_size 변환 - default : (1024, 1024), 적용시 (2048, 2048)\n",
    "# cfg.train_pipeline[2].img_scale=(2048,2048)\n",
    "# cfg.test_pipeline[1].img_scale=(2048,2048)\n",
    "# cfg.val_pipeline[2].img_scale=(2048,2048)\n",
    "\n",
    "# neck 변환 - default : FPN, 적용시 PAFPN\n",
    "# cfg.model.neck=dict(type = 'PAFPN',\n",
    "#                     in_channels=[96, 192, 384, 768],\n",
    "#                     out_channels=256,\n",
    "#                     num_outs=6)\n",
    "\n",
    "# anchor size, 비율 변환 - default : scales = [8], ratios=[0.5, 1.0, 2.0], strides=[2, 4, 8, 16, 32, 64])\n",
    "# cfg.model.rpn_head.anchor_generator=dict(\n",
    "#             type='AnchorGenerator',\n",
    "#             scales=[8],\n",
    "#             ratios=[0.33, 0.5, 1.0, 2.0, 3.0],\n",
    "#             strides=[2, 4, 8, 16, 32, 64])\n",
    "\n",
    "# rpn_proposal 변환 - default : 2000 적용시 : 1000\n",
    "# cfg.model.train_cfg.rpn.rpn_proposal=dict(\n",
    "#             nms_pre=1000,\n",
    "#             max_per_img=1000,\n",
    "#             nms=dict(type='nms', iou_threshold=0.7),\n",
    "#             min_bbox_size=0)\n",
    "\n",
    "# loss변환 - default : cross entropy 적용시 focal loss\n",
    "# cfg.model.rpn_head.loss_cls = dict(type='FocalLoss', loss_weight=1.0)\n",
    "# cfg.model.roi_head.bbox_head[0].loss_cls = dict(\n",
    "#     type='FocalLoss', loss_weight=1.0)\n",
    "# cfg.model.roi_head.bbox_head[1].loss_cls = dict(\n",
    "#     type='FocalLoss', loss_weight=1.0)\n",
    "# cfg.model.roi_head.bbox_head[2].loss_cls = dict(\n",
    "#     type='FocalLoss', loss_weight=1.0)\n",
    "\n",
    "cfg.model.roi_head.bbox_head[0].num_classes = 10\n",
    "cfg.model.roi_head.bbox_head[1].num_classes = 10\n",
    "cfg.model.roi_head.bbox_head[2].num_classes = 10\n",
    "cfg.model.roi_head.mask_head.num_classes = 10\n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.model.train_cfg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d770c06-f056-4028-a19f-5aad709ccc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset= build_dataset(cfg.data.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2138ce-76a9-4bfa-8430-4e169d8a53a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/segmentation/github_workspace/semantic-segmentation-level2-cv-07/mmdetection/mmdet/core/anchor/builder.py:16: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
      "  '``build_anchor_generator`` would be deprecated soon, please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "# build dataset & dataloader\n",
    "\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=cfg.data.samples_per_gpu,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "\n",
    "# checkpoint path\n",
    "checkpoint_path = os.path.join(cfg.work_dir, f'{epoch}.pth')\n",
    "\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg')) # build detector\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu') # ckpt load\n",
    "\n",
    "model.CLASSES = dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4719fb10-0d06-44c0-9f5f-852c170b9926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/819, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/segmentation/github_workspace/semantic-segmentation-level2-cv-07/mmdetection/mmdet/core/anchor/anchor_generator.py:323: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/opt/ml/segmentation/github_workspace/semantic-segmentation-level2-cv-07/mmdetection/mmdet/core/anchor/anchor_generator.py:360: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  '``single_level_grid_anchors`` would be deprecated soon. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 819/819, 8.0 task/s, elapsed: 102s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "output = single_gpu_test(model, data_loader, show_score_thr=0.05) # output 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c8d194e-58b3-4b0b-8f1c-9c40ced313d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'bbox': '/tmp/tmpkkf3i6mg/results.bbox.json', 'proposal': '/tmp/tmpkkf3i6mg/results.bbox.json', 'segm': '/tmp/tmpkkf3i6mg/results.segm.json'}, <TemporaryDirectory '/tmp/tmpkkf3i6mg'>)\n"
     ]
    }
   ],
   "source": [
    "# show output format\n",
    "metric = dataset.format_results(output)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44666e6-eff4-422c-a4c2-844e798d49ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array :\n",
      " (819, 2, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/segmentation/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# show output shape\n",
    "data = np.array(output)\n",
    "print(\"array :\\n\",np.array(data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac10697-ef16-4883-9338-22b2deca4ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/segmentation/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# submission 양식에 맞게 output 후처리\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "coco = COCO(cfg.data.test.ann_file)\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "class_num = 10\n",
    "size = 256\n",
    "\n",
    "for i, out in enumerate(output):\n",
    "    preds_array = np.zeros((size,size), dtype=np.int)\n",
    "    image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "    confidence = 0\n",
    "    for j in range(class_num):\n",
    "        for idx, k in enumerate(out[1][j]) :\n",
    "            mask_array = cv2.resize(mutils.decode(k)*(j+1), (size,size), interpolation = cv2.INTER_NEAREST).astype(int)\n",
    "            # 마스크를 덮어쓰기 안함\n",
    "            # mask_pred = np.where(preds_array == 0, 1, 0)\n",
    "            # preds_array += mask_pred*mask_array\n",
    "            \n",
    "            # 마스크를 덮어쓰기 함\n",
    "            # mask_pred = np.where(mask_array == 0, 1, 0)\n",
    "            # preds_array *= mask_pred\n",
    "            # preds_array += mask_array\n",
    "            \n",
    "            # confidence score을 기준으로 덮어쓰기\n",
    "            if confidence < out[0][j][idx][4] :\n",
    "                mask_pred = np.where(mask_array == 0, 1, 0)\n",
    "                preds_array *= mask_pred\n",
    "                preds_array += mask_array\n",
    "                confidence = out[0][j][idx][4]\n",
    "            else :\n",
    "                mask_pred = np.where(preds_array == 0, 1, 0)\n",
    "                preds_array += mask_pred*mask_array\n",
    "            \n",
    "    file_names.append(image_info['file_name'])\n",
    "    prediction_strings.append(' '.join(str(e) for e in preds_array.flatten().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "670f05b0-b20e-4cf8-b285-9ddac8065aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_01_vt/0021.jpg</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_01_vt/0028.jpg</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_01_vt/0031.jpg</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_01_vt/0032.jpg</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_01_vt/0076.jpg</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_id                                   PredictionString\n",
       "0  batch_01_vt/0021.jpg  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "1  batch_01_vt/0028.jpg  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "2  batch_01_vt/0031.jpg  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "3  batch_01_vt/0032.jpg  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "4  batch_01_vt/0076.jpg  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['image_id'] = file_names\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3def901a-441f-46c5-937e-e43bc44faa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(cfg.work_dir, f'submission_{epoch}.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14b79d3f-abcb-4ee7-b269-558f0064e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried show img but i found good tool\n",
    "# img = '/opt/ml/segmentation/input/data/batch_01_vt/0300.jpg'\n",
    "\n",
    "# model = init_detector(cfg,checkpoint_path)\n",
    "# result = inference_detector(model,img)\n",
    "\n",
    "# show_result_pyplot(model, img, result, score_thr=0.6)# show the image with result\n",
    "# model.show_result(img, result)# save image with result # , out_file='0617.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "002a2349-663b-4d7e-a525-542fabe48be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_id=0\n",
    "# with torch.no_grad():\n",
    "#     for index, outs in enumerate(output):\n",
    "#         oms = torch.argmax(outs, dim=1).detach().cpu().numpy()\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=num_examples, ncols=2, figsize=(10, 4*num_examples), constrained_layout=True)\n",
    "# for row_num in range(num_examples):\n",
    "#     # Original Image\n",
    "#     ax[row_num][0].imshow(temp_images[row_num].permute([1,2,0]))\n",
    "#     ax[row_num][0].set_title(f\"Orignal Image : {image_infos[row_num]['file_name']}\")\n",
    "#     # Pred Mask\n",
    "#     ax[row_num][1].imshow(label_to_color_image(oms[row_num]))\n",
    "#     ax[row_num][1].set_title(f\"Pred Mask : {image_infos[row_num]['file_name']}\")\n",
    "#     ax[row_num][1].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "    \n",
    "# plt.show()\n",
    "\n",
    "#     fig, (ax1) = plt.subplots(nrows=1, ncols=1, figsize=(12, 12))\n",
    "#     ax1.imshow(preds_array)\n",
    "#     ax1.grid(False)\n",
    "#     plt.show()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
