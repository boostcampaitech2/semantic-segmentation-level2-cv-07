{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1629ea-d3ea-47a4-b7f4-094c056909e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.patches import Patch\n",
    "import webcolors\n",
    "\n",
    "plt.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c86bc7-9066-42a5-9d7a-cc8d890c6e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "dataset_path  = '../input/data'\n",
    "anns_file_path = dataset_path + '/' + 'train_all.json'\n",
    "\n",
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "    \n",
    "def load_json_dataset(datset_path='../input/data',json_file='train_all.json'):\n",
    "    anns_file_path = dataset_path + '/' + json_file\n",
    "    # Read annotations\n",
    "    with open(anns_file_path, 'r') as f:\n",
    "        dataset = json.loads(f.read())\n",
    "    return dataset\n",
    "\n",
    "def split_cate_ann_img(dataset):\n",
    "    return dataset['categories'],dataset['annotations'],dataset['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "028ca714-1785-4712-8337-88fa74a00d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=load_json_dataset('../input/data','train.json')\n",
    "dataset_valid=load_json_dataset('../input/data','val.json')\n",
    "dataset_test=load_json_dataset('../input/data','test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ecd8e57-cbc3-4712-b8af-37dff3bc067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_cate,tr_ann,tr_img=split_cate_ann_img(dataset_train)\n",
    "val_cate,val_ann,val_img=split_cate_ann_img(dataset_valid)\n",
    "test_cate,test_ann,test_img=split_cate_ann_img(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "896ceae8-665d-421a-9eaf-0af1bfc5ae21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batch_01_vt/0003.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_img[0]['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c73d4360-f640-4672-aee7-6a1f41327353",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = category_names = ['Backgroud','General trash','Paper','Paper pack',\n",
    "                  'Metal','Glass','Plastic','Styrofoam','Plastic bag',\n",
    "                  'Battery','Clothing']\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        #index값에 맞는 이미지 읽음\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)#bgr->rgb\n",
    "        images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            #마스크를 위한 빈 배열 생성\n",
    "            \n",
    "            # General trash = 1, ... , Cigarette = 10\n",
    "            anns = sorted(anns, key=lambda idx : len(idx['segmentation'][0]), reverse=False)\n",
    "            #면적이 큰 순서대로 정리\n",
    "            \n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks[self.coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "            masks = masks.astype(np.int8)\n",
    "                        \n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            return images, image_infos\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e1c314-cd89-4b16-9ed9-3b08063c792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.17s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.87s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "train_path = dataset_path + '/train.json'\n",
    "val_path = dataset_path + '/val.json'\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                          ToTensorV2()\n",
    "                          ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "\n",
    "# create own Dataset 1 (skip)\n",
    "# validation set을 직접 나누고 싶은 경우\n",
    "# random_split 사용하여 data set을 8:2 로 분할\n",
    "# train_size = int(0.8*len(dataset))\n",
    "# val_size = int(len(dataset)-train_size)\n",
    "# dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=transform)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create own Dataset 2\n",
    "# train dataset\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=1,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=False,\n",
    "                                           drop_last=False)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=1,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=False,\n",
    "                                           drop_last=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=1,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=False,\n",
    "                                           drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa7e16cd-43d2-49e7-9ba9-131f7495669c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>r</th>\n",
       "      <th>g</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backgroud</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>General trash</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paper</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paper pack</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metal</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Glass</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plastic</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Styrofoam</td>\n",
       "      <td>192</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Plastic bag</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Battery</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Clothing</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name    r    g    b\n",
       "0       Backgroud    0    0    0\n",
       "1   General trash  192    0  128\n",
       "2           Paper    0  128  192\n",
       "3      Paper pack    0  128   64\n",
       "4           Metal  128    0    0\n",
       "5           Glass   64    0  128\n",
       "6         Plastic   64    0  192\n",
       "7       Styrofoam  192  128   64\n",
       "8     Plastic bag  192  192  128\n",
       "9         Battery   64   64  128\n",
       "10       Clothing  128    0  192"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_colormap = pd.read_csv(\"/opt/ml/segmentation/baseline_code/class_dict.csv\")\n",
    "class_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54678af-018f-4d78-9582-85e6cf287980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trash_label_colormap():\n",
    "    \"\"\"Creates a label colormap used in Trash segmentation.\n",
    "    Returns:\n",
    "        A colormap for visualizing segmentation results.\n",
    "    \"\"\"\n",
    "    colormap = np.zeros((11, 3), dtype=np.uint8)\n",
    "    for inex, (_, r, g, b) in enumerate(class_colormap.values):\n",
    "        colormap[inex] = [r, g, b]\n",
    "    \n",
    "    return colormap\n",
    "\n",
    "def label_to_color_image(label):\n",
    "    \"\"\"Adds color defined by the dataset colormap to the label.\n",
    "\n",
    "    Args:\n",
    "        label: A 2D array with integer type, storing the segmentation label.\n",
    "\n",
    "    Returns:\n",
    "        result: A 2D array with floating type. The element of the array\n",
    "                is the color indexed by the corresponding element in the input label\n",
    "                to the trash color map.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If label is not of rank 2 or its value is larger than color\n",
    "              map maximum entry.\n",
    "    \"\"\"\n",
    "    if label.ndim != 2:\n",
    "        raise ValueError('Expect 2-D input label')\n",
    "\n",
    "    colormap = create_trash_label_colormap()\n",
    "\n",
    "    if np.max(label) >= len(colormap):\n",
    "        raise ValueError('label value too large.')\n",
    "\n",
    "    return colormap[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7b5d24d-5fbe-4637-9e32-eebcbf0fe008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "080a0fe0-6742-41fe-957f-d8182f1801be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader의 output 결과(image 및 mask) 확인\n",
    "for idx,(imgs, masks, image_infos) in enumerate(train_loader):\n",
    "    image_infos = image_infos[0]\n",
    "    shutil.copyfile(os.path.join(dataset_path,image_infos['file_name']),\n",
    "                   ('../input/mmseg/img_dir/train/'+image_infos['file_name'].replace('/','_')))\n",
    "    # temp_images = imgs`\n",
    "    plt.imsave('../input/mmseg/ann_dir/train/'+image_infos['file_name'].replace('/','_'),masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3876325f-dc46-4727-8317-c5f8164c6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader의 output 결과(image 및 mask) 확인\n",
    "for idx,(imgs, masks, image_infos) in enumerate(val_loader):\n",
    "    image_infos = image_infos[0]\n",
    "    shutil.copyfile(os.path.join(dataset_path,image_infos['file_name']),\n",
    "                   ('../input/mmseg/img_dir/val/'+image_infos['file_name'].replace('/','_')))\n",
    "    # temp_images = imgs\n",
    "    plt.imsave('../input/mmseg/ann_dir/val/'+image_infos['file_name'].replace('/','_'),masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4684406-efc3-4a1b-8874-502d99c82fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader의 output 결과(image 및 mask) 확인\n",
    "for idx,(imgs, image_infos) in enumerate(test_loader):\n",
    "    image_infos = image_infos[0]\n",
    "    shutil.copyfile(os.path.join(dataset_path,image_infos['file_name']),\n",
    "                   ('../input/mmseg/img_dir/test/'+image_infos['file_name'].replace('/','_')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
